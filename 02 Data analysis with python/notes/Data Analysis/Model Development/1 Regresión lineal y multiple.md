## Regresi贸n lineal y regresi贸n lineal multiple
- La regresi贸n lineal se referir谩 a una variable independiente para hacer una predicci贸n.
- La regresi贸n lineal m煤ltiple se referir谩 a m煤ltiples variables independientes para hacer una predicci贸n.

La regresi贸n lineal simple (o SLR) es: Un m茅todo para ayudarnos a comprender la relaci贸n entre dos variables: la ==variable predictora==(independiente) $x$, y la ==variable objetivo== (dependiente) $y$.

Nos gustar铆a llegar a una relaci贸n lineal entre las variables que se muestran aqu铆:

$y = b_{0} + b_{1} * x$
- El par谩metro $b_{0}$ es la intersecci贸n
- El par谩metro $b_{1}$ es la pendiente. 

Cuando ajustamos o entrenamos el modelo, llegaremos arriba con estos par谩metros. Este paso requiere muchas matem谩ticas, por lo que no nos centraremos en esto parte. Aclaremos el paso de predicci贸n. 
Es dif铆cil calcular cu谩nto cuesta un autom贸vil, pero las millas de autopista por gal贸n se encuentran en el manual del propietario. Si asumimos, hay un relaci贸n lineal entre estas variables, podemos usar esta relaci贸n para formular un modelo para determinar el precio del autom贸vil. Si las millas de autopista por gal贸n son 20, nosotros podemos ingresar su valor en el modelo para obtener una predicci贸n de $22,003.

$y = 38423 - 821x$
$y = 38423 - 821(20)$
$y = 22003$

### Fit (Ajuste)
Para determinar la l铆nea, tomamos puntos de datos de nuestro conjunto de datos marcados en rojo aqu铆.
Luego usamos estos puntos de entrenamiento para ajuetar nuestro modelo; ==los resultados de los puntos de entrenamiento son los par谩metros( $b_{0}$ y $b_{1}$ )==. Generalmente almacenamos los puntos de datos en dos dataframe o matrices numpy(_arrays_). 

El valor que nos gustar铆a predecir se llama el _objetivo_, mismo que almacenamos en la matriz $Y$, almacenamos la _variable dependiente_ en el dataframe o matriz $X$. Cada muestra corresponde a una fila diferente en cada dataframe o matriz. 

En muchos casos, muchos factores influyen en c贸mo mucha gente paga por un autom贸vil, por ejemplo, la marca o la antig眉edad del autom贸vil. En este modelo, esta incertidumbre se tiene en cuenta suponiendo que se agrega un peque帽o valor aleatorio al punto
en la l铆nea; Esto se llama ruido. 

La figura de la izquierda muestra la distribuci贸n del ruido, El eje vertical muestra el valor agregado y el eje horizontal ilustra la probabilidad de que se agregue el valor. Por lo general, se agrega un peque帽o valor positivo, o un peque帽o valor negativo. A veces se agregan valores grandes, pero en su mayor parte, los valores agregados son cercanos a cero. 

Podemos resumir el proceso as铆:
- Tenemos un conjunto de puntos de entrenamiento 
- Usamos estos puntos de entrenamiento para encajar o entrenar el modelo y obtener par谩metros: luego usamos estos par谩metros en el modelo
- Ahora tenemos un modelo; usamos el sombrero en la $y$ para denotar que el modelo es una estimaci贸n:
	$\hat{y} = b_{0} + b_{1} * x$
- Podemos usar este modelo para predecir valores que no hemos visto.

Por ejemplo, no tenemos un autom贸vil con 20 millas de autopista por gal贸n, podemos usar nuestro modelo para hacer una predicci贸n para el precio de este autom贸vil. Pero no olvide que nuestro modelo no siempre es correcto.

Podemos ver esto comparando el valor predicho con el valor real.
Tenemos una muestra de 10 millas de autopista por gal贸n, pero el valor predicho no coincide con el valor real. Si la suposici贸n lineal es correcta, este error se debe al ruido pero puede haber otras razones.

1. Para ajustar el modelo en Python, primero importamos el modelo lineal de scikit-learn; 
```py
from sklearn.linear_model import LinearRegression
```
2. Luego crear un objeto de regresi贸n lineal usando el constructor. 
```py
lm = LinearRegression()
```

3. Definimos la variable predictiva y la variable objetivo.
```py
X = df[['highway-mpg']]
Y = df['price']
```
4. Luego use el m茅todo fit para ajustar el modelo y encontrar los par谩metros $b_{0}$ y $b_{1}$. La entrada son las caracter铆sticas y los objetivos.
```py
lm.fit(X,Y)
```
5. Podemos obtener una predicci贸n usando el m茅todo predic.
```py
Yhat = lm.predict(X)
```
La salida es una matriz, la matriz tiene el mismo n煤mero de muestras que la entrada X.
Yhat | X
-----|----
2 	| 5
... | ...
3 | 4

==La intersecci贸n $b_0$ es un atributo del objeto lm== `lm.intercept_`
==La pendiente $b_1$ tambi茅n es un atributo del objeto lm== `lm.coef_`

La relaci贸n entre `price` y `highway-mpg` viene dada por esta ecuaci贸n en negrita: 
$Precio = 38,423.31 - 821.73 * mpg_{highway}$ como la ecuaci贸n que discutimos antes.

### Regresi贸n lineal multiple
La regresi贸n lineal m煤ltiple se utiliza para explicar la relaci贸n entre
- Una variable objetivo (Y) continua, y 
- Dos o m谩s variables predictoras (X).

Si tenemos por ejemplo 4 variables predictoras, 
$\hat{y} = b_0+b_1*x_1+b_2*x_2+b_3*x_3+b_4*x_4$

entonces:
- $b_0$: intercepci贸n (X = 0) 
- $b_1$: el coeficiente o par谩metro de 1:
- $b_2$: el coeficiente del par谩metro 2: y as铆 sucesivamente

Si solo hay dos variables, podemos visualizar los valores. Considere la siguiente funci贸n.
$\hat{y} = 1 + 2*x_1 + 3*x_2$

Las variables 1 y 2 se pueden visualizar en un plano 2D; hagamos un ejemplo. 
La tabla contiene diferentes valores de variables predictoras 1 y 2. La posici贸n de cada punto se coloca en el plano 2D, color codificado en consecuencia. Cada valor de las variables predictoras 1 y 2 se asignar谩 a un nuevo valor  ($\hat{y}$ predecida)

Se asignar谩n los nuevos valores de  ($\hat{y}$ predecida) en la direcci贸n vertical, con altura proporcional al valor que toma.

Podemos ajustar la regresi贸n lineal m煤ltiple de la siguiente manera:
- Podemos extraer las 4 variables predictoras y almacenarlas en la variable Z.
```py
Z = df[['horesepower', 'crumb-weight', 'engine-size', 'highwat-mpg']]
```
- Luego entrenar el modelo como antes de usar el m茅todo de entrenamiento, con las caracter铆sticas o variables dependientes
```py
lm.fit(Z, df['price'])
```
y los objetivos: (dos puntos)
- Tambi茅n podemos obtener una predicci贸n usando el m茅todo de predicci贸n. 
```py
Yhat = lm.predict(X)
```
En este caso, la entrada es una matriz o marco de datos con 4 columnas, 
El n煤mero de filas corresponde al n煤mero de muestras.
$x_1$ | $x_2$ | $x_3$ | $x_4$
----|----|-----------|----
3 | 5 |-4| 3
...|...|...|...
2|4 |2|-4

La salida es una matriz con el mismo n煤mero de elementos que el n煤mero de muestras.
|Yhat|
|----|
|2|
|...|
|3|

1. La intersecci贸n es un atributo del objeto `lm.intercept_`. Y los coeficientes tambi茅n son atributos `lm.coef_`.
1. Es 煤til visualizar la ecuaci贸n, reemplazando los nombres de las variables dependientes con nombres reales.
Esto es id茅ntico al formulario que discutimos anteriormente.
