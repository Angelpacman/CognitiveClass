# Measures for in-Sample Evaluation
Ahora que hemos visto c칩mo podemos evaluar un modelo mediante la visualizaci칩n, queremos valuar num칠ricamente nuestros modelos.
Veamos algunas de las medidas que utilizamos para la evaluaci칩n dentro de la muestra.
Estas medidas son una forma de determinar num칠ricamente qu칠 tan bueno se ajusta el modelo en nuestros datos.
Dos medidas importantes que usamos a menudo para determinar el ajuste de un modelo son: 
- Error cuadr치tico medio (MSE)
- R cuadrado.

## Mean squared error
Para medir el MSE, encontramos la diferencia entre el valor real $y$ y el valor predicho $\hat{y}$ luego elevar al cuadrado el resultado.
En este caso, el valor real es 150; el valor predicho es 50. Restando estos puntos obtenemos 100.
Luego cuadramos el n칰mero.
==Luego tomamos la media o el promedio de todos los errores sumando todos juntos y dividiendo por la cantidad de muestras==.
Para encontrar el MSE en Python, podemos importar el `mean_Squared_error()` de `scikit-learn.metrics`.

La funci칩n "`mean_Squared_error ()`" obtiene dos entradas: el valor real de la variable objetivo y el valor predicho de la variable objetivo.
```py
from sklearn.metrics import mean_squared_error
mean_squared_error(df['price'], Yhat)
```

## R-squared / R^2
==R-cuadrado== tambi칠n se llama coeficiente de determinaci칩n. Es una medida para ==determinar qu칠 tan cerca est치n los datos de la l칤nea de regresi칩n ajustada==. Entonces, 쯤u칠 tan cerca est치n nuestros datos reales de nuestro modelo estimado?
Piense en ello como comparar un modelo de regresi칩n con un modelo simple, es decir, la media de los puntos de datos. Si la variable x es un buen predictor, nuestro modelo deber칤a funcionar mucho mejor que
[con] solo la media.

### Coeficiente de determinaci칩n R^2
En este ejemplo, el promedio de los puntos de datos barra 洧녽  es 6.
El coeficiente de determinaci칩n o R ^ 2 es:
$$
R^2 = \bigl( 1 - \frac{MSE_of_regression_line }{MSE_of_the_average_of_the_data"} \bigr)
$$
1 menos la raz칩n del MSE de la regresi칩n lineal dividida por el MSE del promedio de los puntos de datos. En su mayor parte, se necesita
valores entre 0 y 1.

Veamos un caso en el que la l칤nea proporciona un ajuste relativamente bueno.
La l칤nea azul representa la l칤nea de regresi칩n.
Los cuadrados azules representan el MSE de la l칤nea de regresi칩n.
La l칤nea roja representa el valor promedio de los puntos de datos.
Los cuadrados rojos representan el MSE de la l칤nea roja.
Vemos que el 치rea de los cuadrados azules es mucho m치s peque침a que el 치rea de los cuadrados rojos.
En este caso, debido a que la l칤nea se ajusta bien, el error cuadr치tico medio es peque침o, por lo tanto el numerador es peque침o.

El error cuadr치tico medio de la l칤nea es relativamente grande, por lo que el numerador es grande.
Un n칰mero peque침o dividido por un n칰mero mayor es un n칰mero a칰n menor. 
Llevado a un extremo este valor tiende a cero.
Si conectamos este valor de la diapositiva anterior para R ^ 2, obtenemos un valor cercano a uno, esto significa que la l칤nea se ajusta bien a los datos. Aqu칤 hay un ejemplo de una l칤nea que no se ajusta bien a los datos.
Si solo examinamos el 치rea de los cuadrados rojos en comparaci칩n con los cuadrados azules, vemos el 치rea
Es casi id칠ntico.
La proporci칩n de las 치reas es cercana a uno.
En este caso, el R ^ 2 est치 cerca de cero.
Esta l칤nea tiene el mismo rendimiento que usar el promedio de los puntos de datos, por lo tanto, esta l칤nea no funcion칩 bien.

Encontramos el valor R cuadrado en Python usando el m칠todo `score()`, en el objeto regresi칩n lineal.
Del valor que obtenemos de este ejemplo, podemos decir que aproximadamente el 49.695% de la la variaci칩n del precio se explica por este modelo lineal simple.

==Su valor R ^ 2 generalmente est치 entre 0 y 1, si su R ^ 2 es negativo, puede deberse a un sobreajuste== que discutiremos en el pr칩ximo m칩dulo.

